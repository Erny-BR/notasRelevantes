{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erny-BR/notasRelevantes/blob/main/monitoramentoTreinamentoPyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao definir a arquitetura de uma rede CNN com a classe `torch.nn` no PyTorch, você pode usar vários recursos para acompanhar o fluxo de inputs e pesos (weights) durante o treinamento. Isso é crucial para depurar, entender o comportamento da rede e otimizar seu desempenho. Aqui estão algumas técnicas e ferramentas úteis:\n",
        "\n",
        "**1. Hooks (Ganchos):**\n",
        "\n",
        "*   **O que são:** Hooks são funções que podem ser registradas em `nn.Module`s ou `Tensor`s. Eles são chamados durante o passo `forward` (hook de forward) ou `backward` (hook de backward).\n",
        "*   **Como usar:**\n",
        "    *   **Hooks de Forward:** Permitem inspecionar ou modificar as entradas ou saídas de uma camada durante o passo forward.\n",
        "    *   **Hooks de Backward:** Permitem inspecionar ou modificar os gradientes durante a propagação do gradiente (backpropagation).\n",
        "*   **Exemplo (inspecionando a saída de uma camada):**"
      ],
      "metadata": {
        "id": "VXS1ndlEfcHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# Função hook para imprimir a saída da camada conv1\n",
        "def print_output_hook(module, input, output):\n",
        "    print(f\"Saída da camada {module.__class__.__name__}:\")\n",
        "    print(output)\n",
        "\n",
        "# Registrar o hook na camada conv1\n",
        "hook_handle = model.conv1.register_forward_hook(print_output_hook)\n",
        "\n",
        "# Realizar um passo forward\n",
        "input = torch.randn(1, 3, 28, 28)\n",
        "output = model(input)\n",
        "\n",
        "# Remover o hook quando não for mais necessário\n",
        "hook_handle.remove()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OTNcFS3RfcHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  `torch.nn.Module.named_parameters()` e `torch.nn.Module.named_buffers()`:**\n",
        "\n",
        "*   **O que são:** Métodos que permitem iterar sobre os parâmetros e buffers (como médias e variâncias de batch normalization) de um modelo, juntamente com seus nomes.\n",
        "*   **Como usar:** Útil para imprimir os valores dos pesos, gradientes e outros tensores registrados como parâmetros ou buffers.\n",
        "*   **Exemplo (imprimindo pesos e gradientes):**"
      ],
      "metadata": {
        "id": "nkWWM9v0fcH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Camada: {name} | Tamanho: {param.size()} | Valores : {param[:2]} \\n Gradiente: {param.grad}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Z_uTKBwGfcH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  `torch.autograd.grad_check()` (para verificação de gradientes):**\n",
        "\n",
        "*   **O que é:** Uma função utilitária que ajuda a verificar numericamente a correção dos gradientes calculados durante a backpropagation.\n",
        "*   **Como usar:** Compara os gradientes analíticos calculados pelo PyTorch com estimativas numéricas de gradientes. Útil para depurar implementações customizadas de camadas ou funções de perda.\n",
        "\n",
        "**4.  Visualização com TensorBoard (ou Visdom):**\n",
        "\n",
        "*   **O que é:** O TensorBoard (originalmente do TensorFlow, mas suportado pelo PyTorch) é uma ferramenta de visualização para monitorar o treinamento de redes neurais. O Visdom é uma alternativa mais leve e originalmente criada para PyTorch.\n",
        "*   **Como usar:**\n",
        "    *   **`torch.utils.tensorboard.SummaryWriter`:** Permite registrar escalares (como perda e acurácia), histogramas (distribuição de pesos e ativações), imagens (como mapas de ativação) e o grafo da rede.\n",
        "    *   **Visualizar no navegador:** O TensorBoard (ou Visdom) exibe essas informações em um painel interativo em seu navegador, permitindo que você acompanhe o progresso do treinamento e visualize o comportamento interno da rede."
      ],
      "metadata": {
        "id": "pJMWHMnnfcH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Criar um SummaryWriter\n",
        "writer = SummaryWriter('runs/my_experiment')\n",
        "\n",
        "# ... dentro do loop de treinamento ...\n",
        "\n",
        "# Registrar a perda\n",
        "writer.add_scalar('Loss/train', loss.item(), epoch)\n",
        "\n",
        "# Registrar um histograma dos pesos da camada conv1\n",
        "writer.add_histogram('Conv1/weights', model.conv1.weight, epoch)\n",
        "\n",
        "# Fechar o writer quando terminar\n",
        "writer.close()\n",
        "\n",
        "# Para visualizar:\n",
        "# No terminal, execute: tensorboard --logdir runs\n",
        "# Abra o navegador em: http://localhost:6006/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "W1EIY2O6fcH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Impressão intermitente (com instruções `print`):**\n",
        "\n",
        "*   **O que é:** A maneira mais simples de inspecionar valores é usar instruções `print` dentro do método `forward` da sua classe `nn.Module`.\n",
        "*   **Como usar:** Pode ser útil para verificações rápidas, mas pode gerar muita saída para redes grandes ou durante o treinamento de muitas épocas.\n",
        "\n",
        "**Dicas:**\n",
        "\n",
        "*   **Seja seletivo:** Não tente inspecionar tudo ao mesmo tempo. Concentre-se nas camadas ou tensores mais relevantes para o problema que você está investigando.\n",
        "*   **Use hooks com cuidado:** Hooks podem adicionar sobrecarga computacional, especialmente se forem chamados com frequência. Remova-os quando não forem mais necessários.\n",
        "*   **Combine técnicas:** Use uma combinação dessas técnicas para obter uma compreensão completa do fluxo de dados e pesos em sua rede.\n",
        "\n",
        "Ao usar essas ferramentas e técnicas, você pode obter insights valiosos sobre o funcionamento interno de suas redes CNN no PyTorch, ajudando a depurar, otimizar e melhorar seus modelos de aprendizado profundo. Lembre-se de que a escolha das ferramentas dependerá das necessidades específicas do seu projeto e do que você deseja investigar."
      ],
      "metadata": {
        "id": "gJa4Yr9dfcH3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}